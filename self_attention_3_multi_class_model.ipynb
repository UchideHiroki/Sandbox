{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "np.random.seed(1234)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f4bb2bf6510>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device( \"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self):\n",
    "        self.word2index = defaultdict(int)\n",
    "        self.word2count = defaultdict(int)\n",
    "        self.index2word = defaultdict(str)\n",
    "        self.n_words = 0\n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            self.add_word(word)\n",
    "    \n",
    "    def add_word(self, word):\n",
    "        # 注意!!!!!!!!\n",
    "        # 語彙に対して1からラベルを振っているので、ラベルの最大値のindexは語彙数\n",
    "        # pythonのindexは0からスタートなので、nn.Embeddingは語彙数+1を指定する必要あり\n",
    "        # 普通に0からラベル貼ろうか\n",
    "        # defaultdictなので、間違って未知のkeyを作成してvalue0を増やさないようにする\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 696 ms, sys: 12 ms, total: 708 ms\n",
      "Wall time: 708 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vocab = Vocab()\n",
    "\n",
    "for path in glob.glob('../preprocessed/*.csv'):\n",
    "    series = pd.read_csv(path, header=None, dtype={0: str}, encoding='utf-8').dropna(axis=0)[0]\n",
    "    for sentence in series:\n",
    "        vocab.add_sentence(sentence)\n",
    "\n",
    "# defaultdictは未知のkeyに対応するvalueを要求すると、defaultのvalueを作成してしまう\n",
    "# 後々のバグを防ぐため、通常のdictに変えてロックする\n",
    "vocab.word2index = dict(vocab.word2index)\n",
    "vocab.index2word = dict(vocab.index2word)\n",
    "vocab.word2count = dict(vocab.word2count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def make_padded_array(reviews, vocab=vocab):  \n",
    "    review_list = list()\n",
    "    len_list = list()\n",
    "    for r in reviews:\n",
    "        r = str(r)\n",
    "        review_indexes = [vocab.word2index[w] for w in r.split()]\n",
    "        review_list.append(review_indexes)\n",
    "        len_list.append(len(review_indexes))\n",
    "    \n",
    "    len_array = np.sort(len_list)[::-1].copy() # torch.Tensorは配列逆にしているとエラーを起こすので、コピーする\n",
    "    idxes = np.argsort(len_list)[::-1].copy()\n",
    "    text_array = np.zeros((len(review_list), max(len_list)), dtype=int)\n",
    "    for i, idx in enumerate(idxes):\n",
    "        text_array[i, :len(review_list[idx])] = review_list[idx]\n",
    "    return text_array, len_array, idxes + reviews.index[0] # idxesは0スタートなので、入力reviewsのindexと一致するように調整する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class BatchIterator(object):\n",
    "    def __init__(self, df, batch_len, is_shuffle=True):\n",
    "        self.df = df\n",
    "        self.batch_len = batch_len\n",
    "        self.n_batch = df.shape[0] // batch_len + 1\n",
    "        self.n_data = df.shape[0]\n",
    "        self.is_shuffle = is_shuffle\n",
    "    \n",
    "    def __iter__(self):\n",
    "        if self.is_shuffle:\n",
    "            df = self.df.sample(frac=1).reset_index(drop=True) # DFをシャッフルする\n",
    "        else:\n",
    "            df = self.df\n",
    "        for b_idx in range(0, self.df.shape[0], self.batch_len):\n",
    "            text_batch = df.loc[b_idx:b_idx+self.batch_len-1, \"text\"]\n",
    "            target_batch = df.loc[b_idx:b_idx+self.batch_len-1, \"label\"]\n",
    "            \n",
    "            text_array, len_array, idxes = make_padded_array(text_batch)\n",
    "            target_array = target_batch[idxes].values\n",
    "            \n",
    "            text_tensor = torch.LongTensor(text_array).to(device)\n",
    "            lengths_tensor = torch.LongTensor(len_array).to(device)\n",
    "            target_tensor = torch.LongTensor(target_array).to(device)\n",
    "            \n",
    "            yield text_tensor, lengths_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "やること  \n",
    "\n",
    "単一カテゴリのtrain_dataとtest_dataを作成(ダウンサンプリング)  \n",
    "LSTMモデルを作成(Attention無し)  \n",
    "学習、性能評価(仮の)  \n",
    "\n",
    "将来的には、モデルの作成・保存とモデルの呼び出し・学習・評価を分離した方が良い"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多値分類のデータセットを作る  \n",
    "クラスを0~5に降る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vg_train = pd.read_csv('../preprocessed/vg_train.csv', header=None, encoding='utf-8')\n",
    "hk_train = pd.read_csv('../preprocessed/hk_train.csv', header=None, encoding='utf-8')\n",
    "so_train = pd.read_csv('../preprocessed/so_train.csv', header=None, encoding='utf-8')\n",
    "csj_train = pd.read_csv('../preprocessed/csj_train.csv', header=None, encoding='utf-8')\n",
    "hpc_train = pd.read_csv('../preprocessed/hpc_train.csv', header=None, encoding='utf-8')\n",
    "aa_train = pd.read_csv('../preprocessed/aa_train.csv', header=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1)\n",
      "(1000, 1)\n",
      "(1000, 1)\n",
      "(1000, 1)\n",
      "(1000, 1)\n",
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "for df in [vg_train, hk_train, so_train, csj_train, hpc_train, aa_train]:\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([vg_train, hk_train, so_train, csj_train, hpc_train, aa_train], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 10000\n",
    "train_data['label'] = pd.Series([0]*i+[1]*i+[2]*i+[3]*i+[4]*i+[5]*i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns = ['text', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>because of its compactness my bike lover can a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not much to say after all it is a rail and wor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this app does what it is supposed to do with o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>our old ironing board cover was very thin to b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i bought these for my year old son they fit gr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  because of its compactness my bike lover can a...      0\n",
       "1  not much to say after all it is a rail and wor...      0\n",
       "2  this app does what it is supposed to do with o...      0\n",
       "3  our old ironing board cover was very thin to b...      0\n",
       "4  i bought these for my year old son they fit gr...      0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vg_test = pd.read_csv('../preprocessed/vg_test.csv', header=None, encoding='utf-8')\n",
    "hk_test = pd.read_csv('../preprocessed/hk_test.csv', header=None, encoding='utf-8')\n",
    "so_test = pd.read_csv('../preprocessed/so_test.csv', header=None, encoding='utf-8')\n",
    "csj_test = pd.read_csv('../preprocessed/csj_test.csv', header=None, encoding='utf-8')\n",
    "hpc_test = pd.read_csv('../preprocessed/hpc_test.csv', header=None, encoding='utf-8')\n",
    "aa_test = pd.read_csv('../preprocessed/aa_test.csv', header=None, encoding='utf-8')\n",
    "\n",
    "test_data = pd.concat([vg_test, hk_test, so_test, csj_test, hpc_test, aa_test], axis=0).reset_index(drop=True)\n",
    "\n",
    "i = 10000\n",
    "test_data['label'] = pd.Series([0]*i+[1]*i+[2]*i+[3]*i+[4]*i+[5]*i)\n",
    "test_data = test_data.sample(frac=1).reset_index(drop=True)\n",
    "test_data.columns = ['text', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.44 s, sys: 0 ns, total: 5.44 s\n",
      "Wall time: 5.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text_iterator = BatchIterator(train_data, 1)\n",
    "cnt = 0\n",
    "for te, l, ta in text_iterator:\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基本的にここに準拠  \n",
    "https://qiita.com/itok_msi/items/ad95425b6773985ef959"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding(146467→100)  \n",
    "LSTM(100→32)  \n",
    "Attention  \n",
    "MLP(32→1)  \n",
    "\n",
    "Target(2), neg→[1,0], pos→[0,1]  \n",
    "\n",
    "損失関数に binary_cross_entropy_with_logits を噛ませるので、モデルの出力を[0,1]に制限しなくても良い(sigmoidとlossを別にするより学習が安定する)  \n",
    "予測時には出力層にsigmoid関数を噛ませる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention無しのbiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pack_padded_sequnceを用いた実装\n",
    "class LSTMClassifer(nn.Module):\n",
    "    def __init__(self, emb_dim, h_dim, v_size, n_class=2, bidirectional=True,\n",
    "                 batch_first=True):\n",
    "        super(LSTMClassifer, self).__init__()\n",
    "        self.h_dim = h_dim\n",
    "        self.bi = 2 if bidirectional else 1\n",
    "        self.emb = nn.Embedding(v_size, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, h_dim, batch_first=batch_first, \n",
    "                            bidirectional = bidirectional)\n",
    "        self.affine = nn.Linear(self.h_dim * self.bi, n_class)\n",
    "        \n",
    "    def init_hidden(self, b_size):\n",
    "        h0 = torch.zeros(self.bi, b_size, self.h_dim, device=device)\n",
    "        return (h0, h0) # LSTMはhiddenとcell2つの隠れ層が必要\n",
    "    \n",
    "    def forward(self, sentences, lengths):\n",
    "        hidden, cell = self.init_hidden(sentences.shape[0])\n",
    "        embed = self.emb(sentences)\n",
    "        packed_input = nn.utils.rnn.pack_padded_sequence(embed, lengths, batch_first=True)\n",
    "        output, hidden = self.lstm(packed_input, (hidden, cell))\n",
    "        output = nn.utils.rnn.pad_packed_sequence(output, batch_first=True)[0]\n",
    "        \n",
    "        f_out = output[:, -1, :self.h_dim]\n",
    "        r_out = output[:, 0, self.h_dim:]\n",
    "        output = torch.cat((f_out, r_out), dim=1)\n",
    "        \n",
    "        output = self.affine(output)\n",
    "        output = F.log_softmax(output, dim=1) # (b, n_class), 各データが各クラスに属した場合の対数尤度を計算\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMClassifer(100, 32, vocab.n_words, 6, False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifer2(nn.Module):\n",
    "    def __init__(self, emb_dim, h_dim, v_size, n_class=2, bidirectional=True,\n",
    "                 batch_first=True):\n",
    "        super(LSTMClassifer2, self).__init__()\n",
    "        self.h_dim = h_dim\n",
    "        self.bi = 2 if bidirectional else 1\n",
    "        self.emb = nn.Embedding(v_size, emb_dim)\n",
    "        self.flstm = nn.LSTM(emb_dim, h_dim, batch_first=batch_first, \n",
    "                            bidirectional = False)\n",
    "        self.blstm = nn.LSTM(emb_dim, h_dim, batch_first=batch_first, \n",
    "                            bidirectional = False)\n",
    "        self.affine = nn.Linear(self.h_dim * self.bi, n_class)\n",
    "        \n",
    "    def init_hidden(self, b_size):\n",
    "        h0 = torch.zeros(1, b_size, self.h_dim, device=device)\n",
    "        return (h0, h0) # LSTMはhiddenとcell2つの隠れ層が必要\n",
    "    \n",
    "    def forward(self, sentences, l):\n",
    "        hidden, cell = self.init_hidden(sentences.shape[0])\n",
    "        embed = self.emb(sentences)\n",
    "        fout, (fhidden, fcell) = self.flstm(embed[:,0,:].unsqueeze(1), (hidden, cell))\n",
    "        bout, (bhidden, bcell) = self.blstm(embed[:,-1,:].unsqueeze(1), (hidden, cell))\n",
    "        for i in range(sentences.shape[1]-1):\n",
    "            fout, (fhidden, fcelll) = self.flstm(embed[:,i+1,:].unsqueeze(1), (fhidden, fcell))\n",
    "            bout, (bhidden, bcell) = self.blstm(embed[:,-i-2,:].unsqueeze(1), (bhidden, fcell))\n",
    "        \n",
    "        output = torch.cat((fout, bout), dim=2).squeeze(0)\n",
    "        \n",
    "        output = self.affine(output)\n",
    "        output = F.log_softmax(output, dim=1) # (b, n_class), 各データが各クラスに属した場合の対数尤度を計算\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習関数の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epoch, train_iter, optimizer, log_interval=100):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    all_ = 0\n",
    "    epoch_loss = 0\n",
    "    epoch_ac = 0\n",
    "    \n",
    "    for idx, (x, x_l, y) in enumerate(train_iter):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x, x_l)\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        pred = output.data.max(dim=1)[1]\n",
    "        correct += pred.eq(y).sum().item() # 予測と実測の正答数を加算\n",
    "        epoch_ac += pred.eq(y).sum().item()\n",
    "        all_ += len(y)\n",
    "     \n",
    "        if idx % log_interval == 0:\n",
    "            # バッチ毎の更新で十分にaccuracyが上がっていくので、そこの進捗を表示する\n",
    "            print('time {}, train epoch: {} [{}/{}], acc:{:.4f}, loss:{:.4f}'.format(\n",
    "                datetime.now() - start, epoch, idx+1, train_iter.n_batch, correct/all_, loss))\n",
    "            correct = 0\n",
    "            all_ = 0\n",
    "    return epoch_loss / idx+1, epoch_ac/train_iter.n_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(epoch, test_iter, log_interval=5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        epoch_loss = 0\n",
    "        epoch_ac = 0\n",
    "        for idx, (x, x_l, y) in enumerate(test_iter):\n",
    "            output = model(x, x_l)\n",
    "            loss = F.nll_loss(output, y)\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            pred = output.data.max(dim=1)[1]\n",
    "            correct += pred.eq(y).sum().item()\n",
    "            epoch_ac += pred.eq(y).sum().item()\n",
    "            \n",
    "    if epoch % log_interval == 0:\n",
    "        print('time {}, test epoch: {}, acc:{:.4f}, loss:{:.4f}'.format(\n",
    "        datetime.now() - start, epoch, correct/test_iter.n_data, loss))\n",
    "    return epoch_loss / idx+1, epoch_ac/test_iter.n_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model(review):\n",
    "    review_idxes = [vocab.word2index[w] for w in str(review).split()]\n",
    "    review_tensor = torch.LongTensor(review_idxes).to(device).unsqueeze(0)\n",
    "    length_tensor = torch.LongTensor([len(review_idxes)]).to(device)\n",
    "    \n",
    "    return model(review_tensor, length_tensor).data.max(dim=1)[1].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMClassifer2(100, 32, vocab.n_words, n_class=6).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = BatchIterator(train_data, batch_len=1, is_shuffle=False)\n",
    "test_iter = BatchIterator(test_data, batch_len=1, is_shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "patience = 1\n",
    "n_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 0:00:00.192081, train epoch: 0 [1/6001], acc:0.0000, loss:1.7304\n",
      "time 0:04:18.140005, train epoch: 0 [1001/6001], acc:0.9820, loss:0.0004\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-219a4f08dd07>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(epoch, train_iter, optimizer, log_interval)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-abeca97048b1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentences, l)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mfout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcelll\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mbout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvariable_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdropout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnum_layers\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_lc = []\n",
    "test_lc = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "cnt = 0\n",
    "start = datetime.now()\n",
    "for epoch in range(n_epoch):\n",
    "    train_loss, train_ac = train_model(epoch, test_iter, optimizer, log_interval=1000) # 学習が高速に進む+iter時間かかる→batch毎に進捗プリント\n",
    "    train_lc.append(train_loss)\n",
    "    train_acc.append(train_ac)\n",
    "    \n",
    "    test_loss, test_ac = test_model(epoch, train_iter, log_interval=1)\n",
    "    test_lc.append(test_loss)\n",
    "    test_acc.append(test_ac)\n",
    "    \n",
    "    if epoch > 0:\n",
    "        if test_loss >= min(test_lc[:-1]):\n",
    "            cnt += 1\n",
    "        else:\n",
    "            cnt = 0\n",
    "    \n",
    "    if cnt >= patience:\n",
    "            print('early stopping: epoch {}'.format(epoch))\n",
    "            break\n",
    "    \n",
    "print(\"Done !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=2, figsize=(12,6))\n",
    "axes[0].plot(train_lc, label='train_loss')\n",
    "axes[0].plot(test_lc, label='test_loss')\n",
    "axes[1].plot(train_acc, label='train_ac')\n",
    "axes[1].plot(test_acc, label='test_ac')\n",
    "axes[0].legend()\n",
    "axes[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"../output/bilstm_params.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump([train_loss, test_loss, train_acc, test_acc], open('../output/pytorch_bilstm_metrics.pickle', mode='wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
