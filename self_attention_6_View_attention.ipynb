{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データセットの準備  \n",
    "カテゴリ毎のデータのダウンロード  \n",
    "trainとtest、その他にtextを切り出し  \n",
    "カテゴリ毎に保存  \n",
    "カテゴリ名を指定すると、ダウンサンプリングされたtrain_data, test_dataが返ってくる関数を作成  \n",
    "\n",
    "#### 全ての語彙の格納  \n",
    "全カテゴリのデータの語彙を格納したVocabを作成  \n",
    "Vocabは単語⇄インデックスのやり取りや、語彙数の管理を行う  \n",
    "オンライン学習(未知の単語への対応)はまだよくわかっていない  \n",
    "格納したvocabを保存しておく  \n",
    "\n",
    "#### DataIteratorの作成  \n",
    "train_data, test_dataを元にインスタンスを作成し、forループを回すと自動的にバッチを作成するclassを定義  \n",
    "バッチは全ての単語がインデックスに変換されており、バッチ内で一番長い文の長さに合わせて0埋めされている  \n",
    "\n",
    "#### モデルの作成  \n",
    "入力: 文章  \n",
    "出力: スカラー(所属確率)→2変数ベクトル(多値分類出来るように拡張の余地を残す、やり方をさらっておく)  \n",
    "→2値分類はattention無しでも精度が高過ぎたので、他クラス分類にして問題の難易度をあげる  \n",
    "となるモデルを作成する  \n",
    "※targetはラベル({0,1})を直接入れればOK、これはpytorchの仕様  \n",
    "通常のLSTMと、self attention付きのLSTM2パターンを作成する  \n",
    "\n",
    "#### 学習に必要な関数の定義と学習の実行  \n",
    "損失関数や学習関数、パラメータの設定  \n",
    "同一iteration内で行う処理をまとめた関数の設定  \n",
    "KFoldでデータを5分割して、1つをvalidationとして使用(つまり、1回のiterationで5回学習を行う)  \n",
    "ラベルの偏りが出ないように、ラベルの値毎に層別で分割を行う  \n",
    "同一iterationのvalid_lossは、KFoldした値の平均値を採用\n",
    "learning_curveの監視の仕組みを整備  \n",
    "early stopping  \n",
    "学習  \n",
    "\n",
    "#### 学習済みモデルの保存  \n",
    "モデルとモデルのパラメータを保存  \n",
    "\n",
    "#### モデルの性能評価  \n",
    "test_dataに対して混同行列とF1-scoreを計算して見せる  \n",
    "カテゴリ毎の分類で、いい感じの分類器と微妙な分類器を見せる  \n",
    "上手くいったパターン、上手くいかなかったパターンの文章をself-attention付きで確認する  \n",
    "self-attentionありのモデルと無しのモデルでF1-scoreがどれだけ変わるのかをまとめる  \n",
    "\n",
    "#### 結論  \n",
    "まとめる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notebookを分割した方が良さそう  \n",
    "このノートブックは、Video Gameカテゴリのレビューかを当てるモデルの作成と学習を行う  \n",
    "単一のカテゴリの学習データを作成し、予測を行う  \n",
    "\n",
    "全カテゴリ比較するのしんどそう  \n",
    "とりあえず1カテゴリの分類器作って、余力があれば全カテゴリに展開していく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import glob\n",
    "\n",
    "np.random.seed(1234)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f4888709590>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device( \"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self):\n",
    "        self.word2index = defaultdict(int)\n",
    "        self.word2count = defaultdict(int)\n",
    "        self.index2word = defaultdict(str)\n",
    "        self.n_words = 0\n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            self.add_word(word)\n",
    "    \n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 0\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 3s, sys: 0 ns, total: 1min 3s\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vocab = Vocab()\n",
    "\n",
    "for path in glob.glob('../preprocessed/*.csv'):\n",
    "    series = pd.read_csv(path, header=None, dtype={0: str}, encoding='utf-8').dropna(axis=0)[0]\n",
    "    for sentence in series:\n",
    "        vocab.add_sentence(sentence)\n",
    "\n",
    "# defaultdictは未知のkeyに対応するvalueを要求すると、defaultのvalueを作成してしまう\n",
    "# 後々のバグを防ぐため、通常のdictに変えてロックする\n",
    "vocab.word2index = dict(vocab.word2index)\n",
    "vocab.index2word = dict(vocab.index2word)\n",
    "vocab.word2count = dict(vocab.word2count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vg_test = pd.read_csv('../preprocessed/vg_test.csv', header=None, encoding='utf-8')\n",
    "hk_test = pd.read_csv('../preprocessed/hk_test.csv', header=None, encoding='utf-8')\n",
    "so_test = pd.read_csv('../preprocessed/so_test.csv', header=None, encoding='utf-8')\n",
    "csj_test = pd.read_csv('../preprocessed/csj_test.csv', header=None, encoding='utf-8')\n",
    "hpc_test = pd.read_csv('../preprocessed/hpc_test.csv', header=None, encoding='utf-8')\n",
    "aa_test = pd.read_csv('../preprocessed/aa_test.csv', header=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class LSTMClassifer(nn.Module):\n",
    "    def __init__(self, emb_dim, h_dim, v_size, n_class=2, bidirectional=True,\n",
    "                 batch_first=True):\n",
    "        super(LSTMClassifer, self).__init__()\n",
    "        self.h_dim = h_dim\n",
    "        self.bi = 2 if bidirectional else 1\n",
    "        self.emb = nn.Embedding(v_size, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, h_dim, batch_first=batch_first, \n",
    "                            bidirectional = bidirectional)\n",
    "        \n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Linear(h_dim, 24),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(24, 1)\n",
    "        )\n",
    "        \n",
    "        self.affine = nn.Linear(self.h_dim, n_class)\n",
    "        \n",
    "    def init_hidden(self, b_size):\n",
    "        h0 = torch.zeros(self.bi, b_size, self.h_dim, device=device)\n",
    "        return (h0, h0) # LSTMはhiddenとcell2つの隠れ層が必要\n",
    "    \n",
    "    def forward(self, sentences, lengths):\n",
    "        batch_len = sentences.shape[0]\n",
    "        hidden, cell = self.init_hidden(batch_len)\n",
    "        embed = self.emb(sentences)\n",
    "        packed_input = nn.utils.rnn.pack_padded_sequence(embed, lengths, batch_first=True)\n",
    "        output, hidden = self.lstm(packed_input, (hidden, cell))\n",
    "        output = nn.utils.rnn.pad_packed_sequence(output, batch_first=True)[0] # (b, s, h)\n",
    "        output = output[:, :, :self.h_dim] + output[:, :, self.h_dim:] # 正方向の隠れ層と逆方向の隠れ層を加算\n",
    "        \n",
    "        # Attention\n",
    "        attn = self.attn(output.view(-1, self.h_dim)) # (b,s,h)→(b*s,h)→(b*s,1)\n",
    "        attn = F.softmax(attn.view(batch_len, -1), dim=1).unsqueeze(2) # (b*s,1)→(b,s)→(b,s,1)\n",
    "        \n",
    "        output = (output * attn).sum(dim=1) # (b, s, h)→(b, h)\n",
    "        output = self.affine(output) # (b,h)→(b,c)\n",
    "        output = F.log_softmax(output, dim=1) # (b, c), 各データが各クラスに属した場合の対数尤度を計算\n",
    "        return output, attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 予測関数の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def predict_model(review):\n",
    "    review_idxes = [vocab.word2index[w] for w in str(review).split()]\n",
    "    review_tensor = torch.LongTensor(review_idxes).to(device).unsqueeze(0)\n",
    "    length_tensor = torch.LongTensor([len(review_idxes)]).to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out, attn = model(review_tensor, length_tensor)\n",
    "    \n",
    "    return out.max(dim=1)[1].item(), attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習済みモデルの重み呼び出し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMClassifer(100, 32, vocab.n_words, n_class=6).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClassifer(\n",
       "  (emb): Embedding(210819, 100)\n",
       "  (lstm): LSTM(100, 32, batch_first=True, bidirectional=True)\n",
       "  (attn): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=24, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Linear(in_features=24, out_features=1, bias=True)\n",
       "  )\n",
       "  (affine): Linear(in_features=32, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"../output/\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# htmlを用いた注目単語の可視化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/nn116003/self-attention-classification/blob/master/view_attn.py  \n",
    "このコードを参考にしました"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight(word, attn):\n",
    "    html_color = '#%02X%02X%02X' % (255, int(255*(1 - attn)), int(255*(1 - attn)))\n",
    "    return '<span style=\"background-color: {}\">{}</span>'.format(html_color, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_html(sentence, attns):\n",
    "    html = \"\"\n",
    "    for word, attn in zip(sentence, attns):\n",
    "        html += ' ' + highlight(word, attn)\n",
    "    return html + \"<br><br>\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = csj_test.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is far more beautiful than this picture shows and i have received so many compliments on it when i have worn it i would highly recommend this to others'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = [str(w) for w in s.split()]\n",
    "label, attn = predict_model(s)\n",
    "attn = attn.cpu().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' <span style=\"background-color: #FFEAEA\">this</span> <span style=\"background-color: #FFFCFC\">is</span> <span style=\"background-color: #FFF6F6\">far</span> <span style=\"background-color: #FFE8E8\">more</span> <span style=\"background-color: #FFFEFE\">beautiful</span> <span style=\"background-color: #FFFEFE\">than</span> <span style=\"background-color: #FFECEC\">this</span> <span style=\"background-color: #FFFDFD\">picture</span> <span style=\"background-color: #FFF9F9\">shows</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFF9F9\">i</span> <span style=\"background-color: #FFFEFE\">have</span> <span style=\"background-color: #FFFCFC\">received</span> <span style=\"background-color: #FFFEFE\">so</span> <span style=\"background-color: #FFF1F1\">many</span> <span style=\"background-color: #FFF3F3\">compliments</span> <span style=\"background-color: #FFEBEB\">on</span> <span style=\"background-color: #FFFDFD\">it</span> <span style=\"background-color: #FFFCFC\">when</span> <span style=\"background-color: #FFFDFD\">i</span> <span style=\"background-color: #FFFEFE\">have</span> <span style=\"background-color: #FFA2A2\">worn</span> <span style=\"background-color: #FFFCFC\">it</span> <span style=\"background-color: #FFFDFD\">i</span> <span style=\"background-color: #FFFEFE\">would</span> <span style=\"background-color: #FFFEFE\">highly</span> <span style=\"background-color: #FFFDFD\">recommend</span> <span style=\"background-color: #FFF5F5\">this</span> <span style=\"background-color: #FFF4F4\">to</span> <span style=\"background-color: #FFFEFE\">others</span><br><br>\\n'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mk_html(wl, attn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #FFFDFD\">this</span> <span style=\"background-color: #FFBBBB\">game</span> <span style=\"background-color: #FFFEFE\">was</span> <span style=\"background-color: #FFFEFE\">incredibly</span> <span style=\"background-color: #FFF4F4\">fun</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFEAEA\">play</span> <span style=\"background-color: #FFFCFC\">the</span> <span style=\"background-color: #FFF3F3\">graphics</span> <span style=\"background-color: #FFFEFE\">are</span> <span style=\"background-color: #FFFCFC\">incredible</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFAFA\">the</span> <span style=\"background-color: #FFA3A3\">game</span> <span style=\"background-color: #FFFEFE\">has</span> <span style=\"background-color: #FFFEFE\">twist</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFCFC\">turns</span> <span style=\"background-color: #FFFEFE\">whereever</span> <span style=\"background-color: #FFFEFE\">you</span> <span style=\"background-color: #FFFEFE\">go</span> <span style=\"background-color: #FFFEFE\">i</span> <span style=\"background-color: #FFFEFE\">had</span> <span style=\"background-color: #FFFEFE\">alot</span> <span style=\"background-color: #FFFEFE\">of</span> <span style=\"background-color: #FFFCFC\">fun</span> <span style=\"background-color: #FFFEFE\">sawing</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFFEFE\">monsters</span> <span style=\"background-color: #FFFEFE\">in</span> <span style=\"background-color: #FFFEFE\">half</span> <span style=\"background-color: #FFFEFE\">its</span> <span style=\"background-color: #FFFDFD\">fun</span> <span style=\"background-color: #FFFEFE\">because</span> <span style=\"background-color: #FFFEFE\">you</span> <span style=\"background-color: #FFFEFE\">cant</span> <span style=\"background-color: #FFFEFE\">just</span> <span style=\"background-color: #FFFEFE\">shoot</span> <span style=\"background-color: #FFFEFE\">them</span> <span style=\"background-color: #FFFEFE\">you</span> <span style=\"background-color: #FFFEFE\">have</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">saw</span> <span style=\"background-color: #FFFEFE\">off</span> <span style=\"background-color: #FFFEFE\">their</span> <span style=\"background-color: #FFFEFE\">limbs</span> <span style=\"background-color: #FFFEFE\">awesome</span> <span style=\"background-color: #FFDCDC\">game</span><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #FFFEFE\">this</span> <span style=\"background-color: #FFFEFE\">has</span> <span style=\"background-color: #FFFEFE\">come</span> <span style=\"background-color: #FFFEFE\">in</span> <span style=\"background-color: #FFFEFE\">handy</span> <span style=\"background-color: #FFFEFE\">on</span> <span style=\"background-color: #FFFEFE\">more</span> <span style=\"background-color: #FFFEFE\">than</span> <span style=\"background-color: #FFFEFE\">one</span> <span style=\"background-color: #FFFEFE\">occasion</span> <span style=\"background-color: #FFFDFD\">this</span> <span style=\"background-color: #FFFEFE\">is</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #FFFDFD\">great</span> <span style=\"background-color: #FF0505\">app</span> <span style=\"background-color: #FFFEFE\">i</span> <span style=\"background-color: #FFFEFE\">would</span> <span style=\"background-color: #FFFEFE\">recommend</span> <span style=\"background-color: #FFFEFE\">this</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">anyone</span><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFF4F4\">kettle</span> <span style=\"background-color: #FFFEFE\">i</span> <span style=\"background-color: #FFFEFE\">received</span> <span style=\"background-color: #FFF1F1\">has</span> <span style=\"background-color: #FFFEFE\">smaller</span> <span style=\"background-color: #FFEAEA\">printing</span> <span style=\"background-color: #FFFEFE\">but</span> <span style=\"background-color: #FFFEFE\">it</span> <span style=\"background-color: #FFFEFE\">seems</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">say</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFFEFE\">same</span> <span style=\"background-color: #FFFEFE\">thing</span> <span style=\"background-color: #FFFEFE\">made</span> <span style=\"background-color: #FFFEFE\">in</span> <span style=\"background-color: #FFFDFD\">germany</span> <span style=\"background-color: #FFFEFE\">some</span> <span style=\"background-color: #FFFEFE\">instructions</span> <span style=\"background-color: #FFFDFD\">looks</span> <span style=\"background-color: #FFFEFE\">delicate</span> <span style=\"background-color: #FFFEFE\">but</span> <span style=\"background-color: #FFFEFE\">works</span> <span style=\"background-color: #FFFEFE\">fine</span> <span style=\"background-color: #FFFEFE\">seems</span> <span style=\"background-color: #FFFEFE\">easy</span> <span style=\"background-color: #FFFEFE\">enough</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFF7F7\">clean</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">care</span> <span style=\"background-color: #FFFEFE\">for</span> <span style=\"background-color: #FFFCFC\">the</span> <span style=\"background-color: #FFEBEB\">glass</span> <span style=\"background-color: #FFFEFE\">obviously</span> <span style=\"background-color: #FFFEFE\">gets</span> <span style=\"background-color: #FFFEFE\">hot</span> <span style=\"background-color: #FFFEFE\">but</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFFEFE\">handle</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFD9D9\">lid</span> <span style=\"background-color: #FFFDFD\">stay</span> <span style=\"background-color: #FFFEFE\">cool</span> <span style=\"background-color: #FFFEFE\">enough</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFCFC\">handle</span> <span style=\"background-color: #FFFDFD\">barely</span> <span style=\"background-color: #FFE3E3\">warm</span> <span style=\"background-color: #FFFEFE\">after</span> <span style=\"background-color: #FFA0A0\">boiling</span> <span style=\"background-color: #FFF9F9\">water</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFFEFE\">whistle</span> <span style=\"background-color: #FFFEFE\">isn\\'t</span> <span style=\"background-color: #FFFEFE\">very</span> <span style=\"background-color: #FFFEFE\">loud</span> <span style=\"background-color: #FFFEFE\">but</span> <span style=\"background-color: #FFFEFE\">that\\'s</span> <span style=\"background-color: #FFFEFE\">actually</span> <span style=\"background-color: #FFFEFE\">my</span> <span style=\"background-color: #FFFEFE\">preference</span> <span style=\"background-color: #FFFEFE\">very</span> <span style=\"background-color: #FFFEFE\">happy</span> <span style=\"background-color: #FFFEFE\">with</span> <span style=\"background-color: #FFFEFE\">this</span><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"background-color: #FFEAEA\">this</span> <span style=\"background-color: #FFFCFC\">is</span> <span style=\"background-color: #FFF6F6\">far</span> <span style=\"background-color: #FFE8E8\">more</span> <span style=\"background-color: #FFFEFE\">beautiful</span> <span style=\"background-color: #FFFEFE\">than</span> <span style=\"background-color: #FFECEC\">this</span> <span style=\"background-color: #FFFDFD\">picture</span> <span style=\"background-color: #FFF9F9\">shows</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFF9F9\">i</span> <span style=\"background-color: #FFFEFE\">have</span> <span style=\"background-color: #FFFCFC\">received</span> <span style=\"background-color: #FFFEFE\">so</span> <span style=\"background-color: #FFF1F1\">many</span> <span style=\"background-color: #FFF3F3\">compliments</span> <span style=\"background-color: #FFEBEB\">on</span> <span style=\"background-color: #FFFDFD\">it</span> <span style=\"background-color: #FFFCFC\">when</span> <span style=\"background-color: #FFFDFD\">i</span> <span style=\"background-color: #FFFEFE\">have</span> <span style=\"background-color: #FFA2A2\">worn</span> <span style=\"background-color: #FFFCFC\">it</span> <span style=\"background-color: #FFFDFD\">i</span> <span style=\"background-color: #FFFEFE\">would</span> <span style=\"background-color: #FFFEFE\">highly</span> <span style=\"background-color: #FFFDFD\">recommend</span> <span style=\"background-color: #FFF5F5\">this</span> <span style=\"background-color: #FFF4F4\">to</span> <span style=\"background-color: #FFFEFE\">others</span><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sys' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-dc4492fdf65c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sys' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "sys.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 18:21:58) \\n[GCC 7.2.0]'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pyt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
